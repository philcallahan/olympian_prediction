---
title: "Maximal Margin and Support Vector Classifiers"
author: "Phil Callahan"
date: "xx/xx/xxxx"
output: word_document
---
#========================================================
# Artificial Neural Network  =========================================================
#========================================================

#Lesson 10 ============================================= slide 13

```{r, warning=FALSE}
olympic <- read.csv("olympic_data.csv")
olympic
```
```{r}
#must run log reg Rmd before this cell
MswimANN <- metersOnlyMswim[,-c(9)] #drop resid col
MswimANN
```
```{r}
#standardize data
stdSwim <- data.frame(scale(MswimANN[,1:3]),Year=scale(MswimANN[,5]),
                      Team = MswimANN$Team, binMedal=MswimANN[,8])
stdSwim$Medal <- ifelse(stdSwim$binMedal == 0, "No", "Yes")
stdSwim$binMedal <- NULL
stdSwim$Medal <- factor(stdSwim$Medal)
stdSwim
```
#Lesson 10 ============================================= slide 17

```{r, warning=FALSE}
library(nnet)
set.seed(100)
fitANN1 = nnet(Medal ~ ., 
            data = stdSwim, size = 5, maxit = 1000, MaxNWts=3000) # tweak size to find better fit ========================== 4 is best
# size is num of hidden units, mxit is max num of iterations
```

```{r}
#setup another model
set.seed(100)
fitANN2 = nnet(Medal ~ Age + Height + Weight + Year, 
            data = stdSwim, size = 2, maxit = 1000)
```

```{r, warning=FALSE}
#slide 18
summary(fitANN1)
summary(fitANN1$fitted.values)
```

```{r, warning=FALSE}
#slide18
# install.packages("NeuralNetTools")
library(NeuralNetTools) #has plotnet() fxn
```

```{r, warning=FALSE}
plotnet(fitANN1, struct=struct, circle_col="lightblue")
    axis(1, at=-1:1) #apply grid to find where to put text
    axis(2, at=0:1)
    title("test title")
    # text(-.1, .8, round(fit$wts[1], 2))
    # text(-.45, .8, round(fit$wts[2], 2))
    # text(-.62, .58, round(fit$wts[3], 2))
    # text(-.62, .36, round(fit$wts[4], 2))
    # text(0, .3, round(fit$wts[5], 2))
    # text(-.4, .67, round(fit$wts[6], 2))
    # text(-.44, .5, round(fit$wts[7], 2))
    
```
#Lesson 10 ============================================= slide 19
```{r, warning=FALSE}
#slide 19 ??????????????????
fitANN1$fitted.values[1:25]

maxMedal = apply(fitANN1$fitted.values, 1, which.max)
# maxMedal
maxProb = apply(fitANN1$fitted.values, 1, max)
# maxProb
highProb = which(maxProb > .5)
# highProb
```
#Lesson 10 ============================================= slide 20
```{r, warning=FALSE}
#slide20
dim(stdSwim)[1]
# nrow(stdSwim)
predMedal = rep(NA, dim(stdSwim)[1]) #empty container for predictions
# predMedal[1:25]
predMedal[highProb] = maxMedal[highProb]
# length(maxMedal)
predMedal <- ifelse(is.na(predMedal), "No", "Yes")
# predMedal
conMatANN <- addmargins(table(predMedal, stdSwim$Medal)) #conf matrix
conMatANN
# stdSwim$medal

# length(which(is.na(predMedal))) #count num of probabilities greater than 19.5%

misclassANN = (conMatANN[1,2] + conMatANN[2,1])/conMatANN[3,3]
cat("\nmisclassification rate:", misclassANN)
cat("\nLR Model 3 Accuracy Rate:",round((1-misclassANN)*100,2),"%")
```
size=4 is most parsimonious

# use CV to choose methods =========================================
```{r}
# MswimANN2 <- MswimANN[,c(1:3,5,4,6:8)] #reorder for easy scaling in loop
# MswimANN2$Medal <- ifelse(MswimANN2$binMedal == 0, "No", "Yes")
# MswimANN2$binMedal = NULL
# MswimANN2$Medal <- factor(MswimANN2$Medal)
# # MswimANN2 = MswimANN2[-c(1),] #drop a row for grouping in CV
# MswimANN2
```


#Lesson 10 ============================================= slide 25
```{r, warning=FALSE}
# #p12b ====================================== code takes a while =====================
# nANN = dim(Default)[1]
# kANN = 10 # using 10-fold cross-validation
# groupsANN = c(rep(1:kANN,floor(nANN/kANN)*kANN))  #produces list of group labels
# sizesANN = 1:8
# misclassErrorANN = matrix( , nr = kANN, nc = length(sizesANN) )
# convANN = matrix( , nr = k, nc = length(sizesANN) ) 
# set.seed(4, sample.kind = "Rounding")
# cvgroupsANN = sample(groupsANN,nANN)
# 
# # myMedal.train
# for(iANN in 1:kANN){
#   groupiANN = (cvgroupsANN == iANN)
#   myMedal.train = scale(MswimANN2[!groupiANN, 1:4])
#   myMedal.valid = scale(MswimANN2[groupiANN, 1:4], center = attr(myMedal.train, "scaled:center"), 
#   scale = attr(myMedal.train, "scaled:scale"))
#   
#   myMedal.train = data.frame(myMedal.train)
#   myMedal.valid = data.frame(myMedal.valid)
#   
#   myMedal.train$medal = MswimANN2[!groupi,8]
#   myMedal.valid$medal = MswimANN2[groupi, 8]
# 
#   for(jANN in 1:length(sizesANN)){
# 		fitANN2 = nnet(medal ~ ., 
# 			data = myMedal.train, size = sizesANN[jANN], trace = F, maxit=1000) #only diff is here - added maxit param
# 		  predictionsANN = predict(fitANN2, myMedal.valid, type = "class")
#       misclassErrorANN[iANN, jANN] = length(which(predictionsANN != myMedal.valid[ , 1])) / length(predictionsANN)
#       convANN[iANN, jANN] = fitANN2$convergence
# 	} # end iteration over j
# } # end iteration over i
```
```{r}
# MswimANN2
# myMedal.train
```


#Lesson 10 ============================================= slide 27
```{r, warning=FALSE}
# actSwims = stdSwim$Medal[groupiANN]
# # max(predict(fitANN, stdSwim[groupiANN,]))
# predSwims = ifelse(predict(fitANN, stdSwim[groupiANN,]) > .195, "Yes", "No")
# predSwims[1:10]
# 
# conMatANN2 <- addmargins(table(predSwims, actSwims)) #conf matrix
# conMatANN2
# 
# misclassANN2 = (conMatANN2[1,2] + conMatANN2[2,1])/conMatANN2[3,3]
# cat("\nmisclassification rate:", misclassANN2)
```

```{r}
#still slide27
library(ggplot2)
library(wesanderson)
```

```{r, warning=FALSE, fig.height=5.5, fig.width=6}
gpal <- wes_palette(name = "Zissou1", 3, type = "continuous")
garson(fitANN2) + #garson's algorithm
ggtitle(label="Garson Plot for Variable Importance") +
theme(plot.title = element_text(hjust = 0.5), 
      panel.grid.major = element_blank(), 
      panel.grid.minor = element_blank(),
      panel.background = element_blank(),
      panel.border = element_blank(),
      axis.line = element_line(colour = "black"))+
scale_fill_gradientn(colors = rev(gpal))+
scale_colour_gradientn(colors = rev(gpal))


```
tells us that Petal.Width is most influential while Petal.Length is least
#Lesson 10 ============================================= slide 28
```{r, warning=FALSE, fig.height=5.5, fig.width=6}
lekpal <- wes_palette(name = "Zissou1", 3, type = "continuous")
lekprofile(fitANN2) +
ggtitle(label="Lek Profile for Variable Relationships") +
theme(plot.title = element_text(hjust = 0.5),
      # panel.grid.major = element_blank(), 
      # panel.grid.minor = element_blank(),
      # panel.background = element_blank(),
      # panel.border = element_blank(),
      axis.line = element_line(colour = "black"))+
scale_color_brewer(palette="RdYlBu")

```



#Lesson 10 ============================================= slide 27
```{r, warning=FALSE}

```
#Lesson 10 ============================================= slide 27
```{r, warning=FALSE}

```
#Lesson 10 ============================================= slide 27
```{r, warning=FALSE}

```

```{r, warning=FALSE}

```

```{r, warning=FALSE}

```

```{r, warning=FALSE}

```

```{r, warning=FALSE}

```

```{r, warning=FALSE}

```

```{r, warning=FALSE}

```


